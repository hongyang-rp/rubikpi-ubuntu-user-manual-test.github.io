<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-Document Home/人工智能" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">人工智能 | RUBIK Pi Ubuntu24.04 user Guide</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://rubikpi-ubuntu-user-manual-test.github.io/rubikpi-ubuntu-user-manual-test.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://rubikpi-ubuntu-user-manual-test.github.io/rubikpi-ubuntu-user-manual-test.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://rubikpi-ubuntu-user-manual-test.github.io/rubikpi-ubuntu-user-manual-test.github.io/docs/Document Home/人工智能"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="人工智能 | RUBIK Pi Ubuntu24.04 user Guide"><meta data-rh="true" name="description" content="本章节将介绍Qualcomm AI Runtime SDK的使用流程，Qualcomm AI Runtime SDK可以帮助AI开发者便捷地使用高通的高性能机器学习推理硬件。它支持TensorFlow、PyTorch、ONNX和LiteRT等框架已经训练好的神经网络模型直接或是经过转换在RUBIK Pi 3上快速高效地运行。"><meta data-rh="true" property="og:description" content="本章节将介绍Qualcomm AI Runtime SDK的使用流程，Qualcomm AI Runtime SDK可以帮助AI开发者便捷地使用高通的高性能机器学习推理硬件。它支持TensorFlow、PyTorch、ONNX和LiteRT等框架已经训练好的神经网络模型直接或是经过转换在RUBIK Pi 3上快速高效地运行。"><link data-rh="true" rel="icon" href="/rubikpi-ubuntu-user-manual-test.github.io/img/favicon.png"><link data-rh="true" rel="canonical" href="https://rubikpi-ubuntu-user-manual-test.github.io/rubikpi-ubuntu-user-manual-test.github.io/docs/Document Home/人工智能"><link data-rh="true" rel="alternate" href="https://rubikpi-ubuntu-user-manual-test.github.io/rubikpi-ubuntu-user-manual-test.github.io/docs/Document Home/人工智能" hreflang="en"><link data-rh="true" rel="alternate" href="https://rubikpi-ubuntu-user-manual-test.github.io/rubikpi-ubuntu-user-manual-test.github.io/docs/Document Home/人工智能" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Document Home","item":"https://rubikpi-ubuntu-user-manual-test.github.io/rubikpi-ubuntu-user-manual-test.github.io/docs/category/document-home"},{"@type":"ListItem","position":2,"name":"人工智能","item":"https://rubikpi-ubuntu-user-manual-test.github.io/rubikpi-ubuntu-user-manual-test.github.io/docs/Document Home/人工智能"}]}</script><link rel="alternate" type="application/rss+xml" href="/rubikpi-ubuntu-user-manual-test.github.io/blog/rss.xml" title="RUBIK Pi Ubuntu24.04 user Guide RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/rubikpi-ubuntu-user-manual-test.github.io/blog/atom.xml" title="RUBIK Pi Ubuntu24.04 user Guide Atom Feed"><link rel="stylesheet" href="/rubikpi-ubuntu-user-manual-test.github.io/assets/css/styles.a22174bd.css">
<script src="/rubikpi-ubuntu-user-manual-test.github.io/assets/js/runtime~main.f8e3c7b7.js" defer="defer"></script>
<script src="/rubikpi-ubuntu-user-manual-test.github.io/assets/js/main.8fe239bb.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/rubikpi-ubuntu-user-manual-test.github.io/img/rubik-pi-logo.png"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/rubikpi-ubuntu-user-manual-test.github.io/"><div class="navbar__logo"><img src="/rubikpi-ubuntu-user-manual-test.github.io/img/rubik-pi-logo.png" alt="RUBIK Pi Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/rubikpi-ubuntu-user-manual-test.github.io/img/rubik-pi-logo.png" alt="RUBIK Pi Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">RUBIK Pi Ubuntu24.04 User Guide</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/rubikpi-ubuntu-user-manual-test.github.io/docs/category/document-home">Tutorial</a><a class="navbar__item navbar__link" href="/rubikpi-ubuntu-user-manual-test.github.io/blog">Blog</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/rubikpi-ai" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/rubikpi-ubuntu-user-manual-test.github.io/docs/category/document-home">Document Home</a><button aria-label="Collapse sidebar category &#x27;Document Home&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/rubikpi-ubuntu-user-manual-test.github.io/docs/Document Home/快速入门/">Quick Start</a><button aria-label="Collapse sidebar category &#x27;Quick Start&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/rubikpi-ubuntu-user-manual-test.github.io/docs/Document Home/快速入门/支持配件清单">支持配件清单</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/rubikpi-ubuntu-user-manual-test.github.io/docs/Document Home/快速入门/更新软件">更新软件</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/rubikpi-ubuntu-user-manual-test.github.io/docs/Document Home/快速入门/设置设备">设置设备</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/rubikpi-ubuntu-user-manual-test.github.io/docs/Document Home/快速入门/运行示例应用程序">运行示例应用程序</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/rubikpi-ubuntu-user-manual-test.github.io/docs/Document Home/快速入门/深入研究">深入研究</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/rubikpi-ubuntu-user-manual-test.github.io/docs/Document Home/外设与接口/">外设与接口</a><button aria-label="Expand sidebar category &#x27;外设与接口&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/rubikpi-ubuntu-user-manual-test.github.io/docs/Document Home/IMSDK-TFLite">IMSDK-TFLite</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/rubikpi-ubuntu-user-manual-test.github.io/docs/Document Home/Edge-Impulse">使用 Edge Impulse</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/rubikpi-ubuntu-user-manual-test.github.io/docs/Document Home/开发应用">开发应用程序</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/rubikpi-ubuntu-user-manual-test.github.io/docs/Document Home/机器人开发">机器人开发</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/rubikpi-ubuntu-user-manual-test.github.io/docs/Document Home/摄像头软件">摄像头软件</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/rubikpi-ubuntu-user-manual-test.github.io/docs/Document Home/人工智能">人工智能</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/rubikpi-ubuntu-user-manual-test.github.io/docs/Document Home/ubuntu-desktop-vs-server">ubuntu-desktop-vs-server</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/rubikpi-ubuntu-user-manual-test.github.io/docs/Document Home/IoT 连接">IoT 连接</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/rubikpi-ubuntu-user-manual-test.github.io/docs/Document Home/Linux 内核">Linux 内核</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/rubikpi-ubuntu-user-manual-test.github.io/docs/Document Home/数据手册">数据手册</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/rubikpi-ubuntu-user-manual-test.github.io/docs/Document Home/故障排除">故障排除</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/rubikpi-ubuntu-user-manual-test.github.io/docs/Document Home/开发监管公告">开发监管公告</a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/rubikpi-ubuntu-user-manual-test.github.io/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/rubikpi-ubuntu-user-manual-test.github.io/docs/category/document-home"><span>Document Home</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">人工智能</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>人工智能</h1></header>
<p>本章节将介绍Qualcomm AI Runtime SDK的使用流程，Qualcomm AI Runtime SDK可以帮助AI开发者便捷地使用高通的高性能机器学习推理硬件。它支持TensorFlow、PyTorch、ONNX和LiteRT等框架已经训练好的神经网络模型直接或是经过转换在RUBIK Pi 3上快速高效地运行。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="概述">概述<a href="#概述" class="hash-link" aria-label="Direct link to 概述" title="Direct link to 概述">​</a></h2>
<p>RUBIK Pi 3 Ubuntu  AI/ML 开发流程如下流程图所示：</p>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-24-da667333f43f2f5dbc54062fc7b1d52e.png" width="2232" height="256" class="img_ev3q"></p>
<p>上面的AI/ML 开发流程大致分为两个步骤：</p>
<p>步骤 1</p>
<p>■ 编译并优化来自第三方 AI 框架的模型,以便在 RUBIK Pi 3上高效运行。例如,可以将 TensorFlow 模型导出为 TFLite 模型。可以对模型文件针对推理硬件来做量化、细调性能和精确度等特殊的定制操作。</p>
<p>步骤 2</p>
<p>编译应用程序,使用优化后的模型在设备上运行推理 </p>
<p>■ 将 AI 模型集成到用例 pipeline 中。</p>
<p>■ 交叉编译应用程序,生成使用依赖库的可执行二进制文件。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="软件和硬件架构">软件和硬件架构<a href="#软件和硬件架构" class="hash-link" aria-label="Direct link to 软件和硬件架构" title="Direct link to 软件和硬件架构">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="ai整体框架">AI整体框架<a href="#ai整体框架" class="hash-link" aria-label="Direct link to AI整体框架" title="Direct link to AI整体框架">​</a></h3>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-19-7dc987e876c7f8c9d496531e740f2f92.png" width="1395" height="875" class="img_ev3q"></p>
<p>开发人员可以从ONNX、PyTorch、TensorFlow或TFLite中引入模型，使用Qualcomm AI Runtime SDK将这些模型高效地运行在RUBIK Pi 3的人工智能硬件-HTP（NPU）、GPU、CPU上。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="ai硬件">AI硬件<a href="#ai硬件" class="hash-link" aria-label="Direct link to AI硬件" title="Direct link to AI硬件">​</a></h3>
<p>■ Qualcomm Kryo™ CPU- 一流的 CPU ,具有高性能和卓越的能效。</p>
<p>■ Qualcomm Adreno GPU- 适合在需要平衡功耗与性能的情况下执行 AI 工作负载。 AI 工作负载可以通过 OpenCL 内核进行加速。 GPU 还可用于加速模型预处理 / 后处理。</p>
<p>■ Qualcomm Hexagon 张量处理器 (HTP)- 又称 NPU/DSP/HMX ,适合低功耗、高性地能执行AI 工作负载。为优化性能,需要对预训练模型进行量化,使其达到支持的任一种精度。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="ai-软件">AI 软件<a href="#ai-软件" class="hash-link" aria-label="Direct link to AI 软件" title="Direct link to AI 软件">​</a></h3>
<p>AI软件堆栈包含多种 SDK ,帮助AI开发者方便地利用RUBIK Pi 3的AI 硬件加速器的强大功能。开发人员可以自己选择的一种 SDK 来部署 AI 工作负载。预训练模型在运行之前需要将其转换为所选 SDK 所支持的可执行格式 (TFLite 模型除外)。 TFLite 模型可以使用 TFLite Delegate 直接运行。</p>
<p>■ <strong>LiteRT</strong></p>
<p>LiteRT 模型可以使用以下 Delegate在 RUBIK Pi 3 的硬件上本地执行。</p>
<table><thead><tr><th>Delegate</th><th>硬件加速器</th></tr></thead><tbody><tr><td>AI Engine Direct Delegate (QNN Delegate)</td><td>CPU 、 GPU 和 HTP</td></tr><tr><td>XNNPACK Delegate</td><td>CPU</td></tr><tr><td>GPU Delegate</td><td>GPU</td></tr></tbody></table>
<p>■<strong>Qualcomm 神经网络处理引擎</strong></p>
<p>Qualcomm 神经网络处理引擎 (Qualcomm Neural Processing Engine SDK ，也称为SNPE) 是一种用于执行深度神经网络的软件加速 运行时 。SNPE SDK提供相关工具来对神经网络进行转换、量化,并在 CPU 、 GPU 和 HTP 等硬件加速器上对其进行加速。</p>
<p>■ <strong>Qualcomm AI Engine Direct (QNN)</strong></p>
<p>Qualcomm AI Engine Direct是为 AI/ML 场景用例使用Rubik Pi 3的AI加速器硬件而设计的一种软件架构。</p>
<p>该架构旨在提供统一的 API ,模块和可扩展的预加速库,从而基于这种可重用的结构打造全栈 AI 解决方案。它可为Qualcomm 神经网络处理 SDK(SNPE) 、 TFLite AI Engine Direct Delegate 等运行时提供支持。</p>
<p>■ <strong>AI Model Efficiency Toolkit (AIMET)</strong></p>
<p>这是一个用于优化（压缩和量化）训练好的神经网络模型的开源库。并且该库是一个复杂的SDK旨在生成优化的量化模型，适用于高阶开发者。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="编译和优化模型">编译和优化模型<a href="#编译和优化模型" class="hash-link" aria-label="Direct link to 编译和优化模型" title="Direct link to 编译和优化模型">​</a></h2>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-1-4f819a3ff6a64892ba61b28315c0196b.png" width="2232" height="256" class="img_ev3q"></p>
<p>开发者可以使用以下两种方式中的任意一种方式来编译和优化自己的模型。</p>
<table><thead><tr><th><strong>■ AI Hub</strong></th><th></th></tr></thead><tbody><tr><td><strong>■ AI 软件堆栈</strong></td><td>直接移植LiteRT AI的模型到RUBIK Pi 3设备上。使用一体化、易于定制的Qualcomm AI Runtime（QAIRT）SDK移植您的模型。</td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="ai-hub">AI Hub<a href="#ai-hub" class="hash-link" aria-label="Direct link to AI Hub" title="Direct link to AI Hub">​</a></h3>
<p>AI Hub 提供了帮助开发人员针对视觉、音频和语音用例的机器学习模型在设备上进行优化、验证和部署的方法和途径。</p>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-2-d77a04e5374c774907be5b81eca22fa0.png" width="1242" height="516" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="环境配置">环境配置<a href="#环境配置" class="hash-link" aria-label="Direct link to 环境配置" title="Direct link to 环境配置">​</a></h4>
<ol>
<li>
<p>在您的计算机上安装miniconda和配置Python环境。</p>
<ol>
<li>
<p>安装miniconda。
从<a href="https://www.anaconda.com/download" target="_blank" rel="noopener noreferrer">miniconda</a>官网下载miniconda并安装。</p>
</li>
<li>
<p>打开命令行窗口。</p>
</li>
</ol>
</li>
</ol>
<div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Windows</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">macOS/Linux</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><p>安装完成后,通过 Start 菜单打开 <a href="https://docs.conda.io/projects/miniconda/en/latest/miniconda-install.html" target="_blank" rel="noopener noreferrer">Anaconda</a>提示符窗口。</p></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><p>安装完成后,打开一个新的 shell 窗口。</p></div></div></div>
<ol start="3">
<li>为AI Hub配置一个Python的虚拟环境</li>
</ol>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">conda activate</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">conda create python=3.10 -n qai_hub</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">conda activate qai_hub</span><br></span></code></pre></div></div>
<ol start="2">
<li>
<p>安装 AI Hub Python 客户端。</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip3 install qai-hub</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pip3 install &quot;qai-hub[torch]&quot;</span><br></span></code></pre></div></div>
</li>
<li>
<p>登录 AI Hub。</p>
<p>前往 <a href="https://aihub.qualcomm.com/" target="_blank" rel="noopener noreferrer">AI Hub</a> 并使用 Qualcomm ID 登录,查看所创建作业的相关信息。</p>
<p>登录后,导航至 Account &gt; Settings &gt; API Token 。此时应提供一个可用于配置客户端的 API 令牌。</p>
<ol start="4">
<li>在终端,使用以下命令通过 API 令牌配置客户端。</li>
</ol>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">qai-hub configure --api_token &lt;INSERT_API_TOKEN&gt;</span><br></span></code></pre></div></div>
<p>然后使用下面命令查看支持设备列表，验证 AI Hub Python 客户端是否安装成功：</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">qai-hub list-devices</span><br></span></code></pre></div></div>
<p>出现如下结果说明 AI Hub Python 客户端安装成功：</p>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-20-fa25dcb50279a4e5143c9fdeee4dbcfa.png" width="1558" height="1015" class="img_ev3q"></p>
</li>
</ol>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="ai-hub-工作流程">AI Hub 工作流程<a href="#ai-hub-工作流程" class="hash-link" aria-label="Direct link to AI Hub 工作流程" title="Direct link to AI Hub 工作流程">​</a></h4>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="使用预优化模型">使用预优化模型<a href="#使用预优化模型" class="hash-link" aria-label="Direct link to 使用预优化模型" title="Direct link to 使用预优化模型">​</a></h5>
<ol>
<li>
<p>导航到 <a href="https://aihub.qualcomm.com/iot/models" target="_blank" rel="noopener noreferrer">AI Hub Model Zoo</a> ,访问适用于 RUBIK Pi 3的预优化模型。</p>
</li>
<li>
<p>从左侧窗格中选择 Qualcomm QCS6490 作为芯片组,筛选适用于 RUBIK Pi 3的模型。</p>
</li>
<li>
<p>从筛选结果视图中选择一个模型以导航到模型页面。</p>
</li>
<li>
<p>在模型页面上,从下拉列表中选择 Qualcomm QCS6490 ,然后选择 TorchScript &gt; TFLite 路径。</p>
</li>
<li>
<p>点击下载按钮后开始模型下载。下载的模型已经过预先优化,可直接开发用户自己的应用程序。</p>
</li>
</ol>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="引入用户自己的模型">引入用户自己的模型<a href="#引入用户自己的模型" class="hash-link" aria-label="Direct link to 引入用户自己的模型" title="Direct link to 引入用户自己的模型">​</a></h5>
<ol>
<li>
<p>选择 PyTorch 或 Onnx 格式的预训练模型。</p>
</li>
<li>
<p>使用 Python API 将模型提交至 AI Hub 以进行编译或优化。提交编译作业时,必须选择设备或芯片组以及目标 runtime 才能编译模型。 RUBIK Pi 3支持TFLite runtime 。</p>
<table><thead><tr><th><strong>芯片组</strong></th><th><strong>Runtime</strong></th><th><strong>CPU</strong></th><th><strong>GPU</strong></th><th><strong>HTP</strong></th></tr></thead><tbody><tr><td>QCS6490</td><td>TFLite</td><td>INT8,FP16, FP32</td><td>FP16,FP32</td><td>NT8,INT16</td></tr></tbody></table>
<p>提交后, AI Hub 会为该作业生成一个唯一的 ID 。用户可以使用此作业 ID 查看作业详情。</p>
</li>
<li>
<p>AI Hub 会根据选择的设备和 runtime 对模型进行优化。或者,也可以提交作业在源自云设备集群且已经过配置的实际设备上对优化模型进行分析或推理(使用 Python API )。</p>
<p>– 性能分析:在已配置的设备上对模型进行基准测试并提供统计数据,包括层级的平均推理时间、 runtime 配置等。</p>
<p>– 推理:在推理作业执行过程中,使用优化模型基于提交的数据进行推理,即在已配置的云设备上运行该模型。</p>
</li>
<li>
<p>提交的每项作业都可以在 AI Hub 门户中进行重新回顾。提交编译作业时,将会提供优化模型的可用下载链接。然后,该优化模型可以部署在 RUBIK Pi 3本地开发设备上。</p>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="litert">LiteRT<a href="#litert" class="hash-link" aria-label="Direct link to LiteRT" title="Direct link to LiteRT">​</a></h3>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-3-73a8c94a2299fe8ec85ac4ab64e111a5.png" width="1520" height="1012" class="img_ev3q"></p>
<p>LiteRT是一个用于在设备上进行AI推理的开源深度学习框架。 LiteRT 可优化模型的延迟、模型尺寸、功耗等,帮助开发人员在移动、嵌入式和边缘平台上运行自己的模型。RUBIK Pi 3支持通过下方列出的 TFLite Delegate 在本地执行 TFLite 模型。</p>
<table><thead><tr><th>Delegate</th><th>加速器</th></tr></thead><tbody><tr><td>AI Engine Direct Delegate (QNN Delegate)</td><td>CPU 、 GPU 和 HTP</td></tr><tr><td>XNNPack Delegate</td><td>CPU</td></tr><tr><td>GPU Delegate</td><td>GPU</td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="qualcomm-ai-runtime-sdk">Qualcomm AI Runtime SDK<a href="#qualcomm-ai-runtime-sdk" class="hash-link" aria-label="Direct link to Qualcomm AI Runtime SDK" title="Direct link to Qualcomm AI Runtime SDK">​</a></h3>
<p>Qualcomm AI Runtime SDK是一个多功能SDK，用于将ML模型移植到Qualcomm（RUBIK Pi 3）加速硬件上运行。SDK包含高通神经处理引擎（Qualcomm Neural Processing Engine ，即 SNPE）和AI Engine Direct（也称为QNN）所提供的工具，用于转换和量化PyTorch和TensorFlow等的模型，以及在CPU、GPU和HTP等运行时上运行这些模型。了解更多关于<a href="https://docs.qualcomm.com/bundle/publicresource/topics/80-63442-2/" target="_blank" rel="noopener noreferrer">SNPE</a>和<a href="https://docs.qualcomm.com/bundle/publicresource/topics/80-63442-50/" target="_blank" rel="noopener noreferrer">QNN</a>。</p>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-4-a7105a57f4f5366f9768eda099b3a933.png" width="1456" height="1746" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="aiml-示例程序">AI/ML 示例程序<a href="#aiml-示例程序" class="hash-link" aria-label="Direct link to AI/ML 示例程序" title="Direct link to AI/ML 示例程序">​</a></h2>
<p>AI/ML 示例程序展示了在 RUBIK Pi 3设备上从实时摄像头或是本地视频文件馈送数据然后运行模型的实际场景。下文将详述运行示例程序的步骤。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="前提准备">前提准备<a href="#前提准备" class="hash-link" aria-label="Direct link to 前提准备" title="Direct link to 前提准备">​</a></h3>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="软件包的安装">软件包的安装<a href="#软件包的安装" class="hash-link" aria-label="Direct link to 软件包的安装" title="Direct link to 软件包的安装">​</a></h5>
<p>参见<a href="/rubikpi-ubuntu-user-manual-test.github.io/docs/Document Home/快速入门/运行示例应用程序">运行示例应用程序</a>中内容，确保里面的的示例程序可以正常运行。</p>
<p>桌面版本需要使用如下方式启动 Weston。</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">systemctl stop gdm</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sudo dpkg-reconfigure weston-autostart</span><br></span></code></pre></div></div>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="模型文件和label文件下载">模型文件和label文件下载<a href="#模型文件和label文件下载" class="hash-link" aria-label="Direct link to 模型文件和label文件下载" title="Direct link to 模型文件和label文件下载">​</a></h5>
<p><strong>LiteRT 的示例程序名称和对应的模型文件，label文件列表：</strong></p>
<table><thead><tr><th>示例应用程序</th><th>所需模型</th><th>所需label文件</th></tr></thead><tbody><tr><td>image-classification-LiteRT-from-camera/file</td><td>resnet101-resnet101-w8a8.tflite</td><td>classification_0.labels</td></tr><tr><td>object-detection-LiteRT-from-camera/file</td><td>yolov8_det_quantized.tflite</td><td>yolov8.labels</td></tr><tr><td>image-segmentation-LiteRT-from-camera/file</td><td>deeplabv3_plus_mobilenet_quantized.tflite</td><td>deeplabv3_resnet50.labels</td></tr><tr><td>pose-detection-LiteRT-from-camera/file</td><td>hrnet_pose_quantized.tflite</td><td>hrnet_pose.labels</td></tr></tbody></table>
<p><strong>SNPE的示例程序名称和对应的模型文件，label文件列表：</strong></p>
<table><thead><tr><th>示例应用程序</th><th>所需模型</th><th>所需label文件</th></tr></thead><tbody><tr><td>image-classification-LiteRT-from-camera/file</td><td>inceptionv3.dlc</td><td>classification.labels</td></tr><tr><td>object-detection-LiteRT-from-camera/file</td><td>yolonas.dlc</td><td>yolonas.labels</td></tr></tbody></table>
<ul>
<li>
<p><a href="https://thundercomm.s3.dualstack.ap-northeast-1.amazonaws.com/uploads/web/rubik-pi-3/tools/ai_sample_app_model_label.zip" target="_blank" rel="noopener noreferrer">点击下载</a>示例程序需要的模型文件和label文件的压缩包ai_sample_app_model_label.zip。</p>
</li>
<li>
<p>您可以使用如下命令将压缩包内的所有模型文件和label文件一次性全部都推到板子的opt目录下</p>
</li>
</ul>
<div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Ubuntu</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Windows</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">adb push ./* /opt</span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">adb push  /opt</span><br></span></code></pre></div></div></div></div></div>
<ul>
<li>您也可以在使用下面示例程序时单独推示例程序需要的模型文件和label文件到板子内的/opt目录下</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="litert示例程序">LiteRT示例程序:<a href="#litert示例程序" class="hash-link" aria-label="Direct link to LiteRT示例程序:" title="Direct link to LiteRT示例程序:">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="通过摄像头获取图像信息实现-ai-功能的示例程序">通过摄像头获取图像信息实现 AI 功能的示例程序<a href="#通过摄像头获取图像信息实现-ai-功能的示例程序" class="hash-link" aria-label="Direct link to 通过摄像头获取图像信息实现 AI 功能的示例程序" title="Direct link to 通过摄像头获取图像信息实现 AI 功能的示例程序">​</a></h4>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="图像分类image-classification-litert-from-camera">图像分类(image-classification-LiteRT-from-camera)<a href="#图像分类image-classification-litert-from-camera" class="hash-link" aria-label="Direct link to 图像分类(image-classification-LiteRT-from-camera)" title="Direct link to 图像分类(image-classification-LiteRT-from-camera)">​</a></h5>
<p>该示例程序使用camera实时获取图像并传送给LiteRT使用HTP推理resnet101-resnet101-w8a8.tflite模型，然后将分类结果和图像信息通过weston显示在显示器上。具体pipeline参见下面框图。</p>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-5-caa5f15bee0560a6dcb8d932f1962a74.png" width="2964" height="1130" class="img_ev3q"></p>
<ul>
<li>从模型压缩包内将该示例需要的模型文件和label文件push到/opt目录下面</li>
</ul>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">adb push resnet101-resnet101-w8a8.tflite /opt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">adb push classification.labels /opt</span><br></span></code></pre></div></div>
<ul>
<li>执行下面命令运行该示例程序</li>
</ul>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sudo -i</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export XDG_RUNTIME_DIR=/run/user/$(id -u ubuntu)/ &amp;&amp; export WAYLAND_DISPLAY=wayland-1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">gst-launch-1.0 -e --gst-debug=1 qtiqmmfsrc name=camsrc camera=0  ! video/x-raw,format=NV12 ! tee name=split ! queue ! qtivcomposer name=mixer ! queue ! fpsdisplaysink sync=true signal-fps-measurements=true text-overlay=true video-sink=&quot;waylandsink fullscreen=true&quot; split. ! queue ! qtimlvconverter ! queue ! qtimltflite name=tf_3 delegate=external external-delegate-path=libQnnTFLiteDelegate.so external-delegate-options=&quot;QNNExternalDelegate,backend_type=htp,htp_device_id=(string)0,htp_performance_mode=(string)2,htp_precision=(string)1;&quot;  model=/opt/resnet101-resnet101-w8a8.tflite ! queue ! qtimlvclassification threshold=51.0 results=5 module=mobilenet labels=/opt/classification_0.labels extra-operation=softmax constants=&quot;Inception,q-offsets=&lt;-38.0&gt;,q-scales=&lt;0.17039915919303894&gt;;&quot; ! video/x-raw,format=BGRA,width=640,height=360 ! queue ! mixer. </span><br></span></code></pre></div></div>
<ul>
<li>效果图如下：</li>
</ul>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-18-5d1382a3bbb82a0dc9cf91b347fbb60b.jpg" width="1280" height="960" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="目标检测object-detection-litert-from-camera">目标检测(object-detection-LiteRT-from-camera)<a href="#目标检测object-detection-litert-from-camera" class="hash-link" aria-label="Direct link to 目标检测(object-detection-LiteRT-from-camera)" title="Direct link to 目标检测(object-detection-LiteRT-from-camera)">​</a></h5>
<p>该示例程序使用camera实时获取图像并传送给LiteRT使用HTP推理yolov8_det_quantized.tflite模型，然后将目标检测结果和图像信息通过weston显示在显示器上。具体pipeline参见下面框图。</p>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-6-b24958dcb8b079935aa889bd43974351.png" width="2964" height="1130" class="img_ev3q"></p>
<ul>
<li>从模型压缩包内将该示例需要的模型文件和label文件push到/opt目录下面</li>
</ul>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">adb push yolov8_det_quantized.tflite /opt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">adb push yolov8.labels /opt</span><br></span></code></pre></div></div>
<ul>
<li>执行下面命令运行该示例程序</li>
</ul>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sudo -i</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export XDG_RUNTIME_DIR=/run/user/$(id -u ubuntu)/ &amp;&amp; export WAYLAND_DISPLAY=wayland-1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">gst-launch-1.0 -e --gst-debug=1 qtiqmmfsrc name=camsrc camera=0 ! video/x-raw,format=NV12 ! tee name=split ! queue ! qtivcomposer name=mixer ! queue ! fpsdisplaysink sync=true signal-fps-measurements=true text-overlay=true video-sink=&quot;waylandsink fullscreen=true&quot; split. ! queue ! qtimlvconverter ! queue ! qtimltflite delegate=external external-delegate-path=libQnnTFLiteDelegate.so external-delegate-options=&quot;QNNExternalDelegate,backend_type=htp;&quot; model=/opt/yolov8_det_quantized.tflite ! queue ! qtimlvdetection threshold=75.0 results=10 module=yolov8 labels=/opt/yolov8.labels constants=&quot;YOLOv8,q-offsets=&lt;21.0, 0.0, 0.0&gt;,    q-scales=&lt;3.0546178817749023, 0.003793874057009816, 1.0&gt;;&quot; ! video/x-raw,format=BGRA,width=640,height=360 ! queue ! mixer.</span><br></span></code></pre></div></div>
<ul>
<li>效果图如下：</li>
</ul>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-22-29fb4dee3b1a7948034a312f8bfa8709.png" width="956" height="486" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="语义分割image-segmentation-litert-from-camera">语义分割(image-segmentation-LiteRT-from-camera)<a href="#语义分割image-segmentation-litert-from-camera" class="hash-link" aria-label="Direct link to 语义分割(image-segmentation-LiteRT-from-camera)" title="Direct link to 语义分割(image-segmentation-LiteRT-from-camera)">​</a></h5>
<p>该示例程序使用camera实时获取图像并传送给LiteRT使用HTP推理deeplabv3_plus_mobilenet_quantized.tflite模型，然后将语义分割结果和图像信息通过weston显示在显示器上。具体pipeline参见下面框图。</p>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-7-740230a8184f0a3fb841f1ec41d63b04.png" width="2964" height="1130" class="img_ev3q"></p>
<ul>
<li>从模型压缩包内将该示例需要的模型文件和label文件push到/opt目录下面</li>
</ul>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">adb push deeplabv3_plus_mobilenet_quantized.tflite /opt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">adb push deeplabv3_resnet50.labels  /opt</span><br></span></code></pre></div></div>
<ul>
<li>执行下面命令运行该示例程序</li>
</ul>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sudo -i</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export XDG_RUNTIME_DIR=/run/user/$(id -u ubuntu)/ &amp;&amp; export WAYLAND_DISPLAY=wayland-1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">gst-launch-1.0 -e --gst-debug=1 qtiqmmfsrc name=camsrc camera=0 ! video/x-raw,format=NV12 ! tee name=split ! queue ! qtivcomposer name=mixer sink_1::alpha=0.5 ! queue ! fpsdisplaysink sync=true signal-fps-measurements=true text-overlay=true video-sink=&quot;waylandsink fullscreen=true&quot; split. ! queue ! qtimlvconverter ! queue ! qtimltflite delegate=external external-delegate-path=libQnnTFLiteDelegate.so external-delegate-options=&quot;QNNExternalDelegate,backend_type=htp;&quot; model=/opt/deeplabv3_plus_mobilenet_quantized.tflite ! queue ! qtimlvsegmentation module=deeplab-argmax labels=/opt/deeplabv3_resnet50.labels constants=&quot;deeplab,q-offsets=&lt;-61.0&gt;,q-scales=&lt;0.06232302635908127&gt;;&quot; ! video/x-raw,format=BGRA,width=256,height=144 ! queue ! mixer.</span><br></span></code></pre></div></div>
<ul>
<li>效果图如下：</li>
</ul>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-23-1a966d6b57441eb8d7c1e07a78935316.png" width="918" height="519" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="姿态识别pose-detection-litert-from-camera">姿态识别(pose-detection-LiteRT-from-camera)<a href="#姿态识别pose-detection-litert-from-camera" class="hash-link" aria-label="Direct link to 姿态识别(pose-detection-LiteRT-from-camera)" title="Direct link to 姿态识别(pose-detection-LiteRT-from-camera)">​</a></h5>
<p>该示例程序使用camera实时获取图像并传送给LiteRT使用HTP推理hrnet_pose_quantized.tflite模型，然后将人体姿态识别结果和图像信息通过weston显示在显示器上。具体pipeline参见下面框图。</p>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-8-ee38c01e8a372e5da97a6f7aef4e0aac.png" width="2964" height="1130" class="img_ev3q"></p>
<ul>
<li>从模型压缩包内将该示例需要的模型文件和label文件push到/opt目录下面</li>
</ul>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">adb push hrnet_pose_quantized.tflite /opt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">adb push hrnet_pose.labels  /opt</span><br></span></code></pre></div></div>
<ul>
<li>执行下面命令运行该示例程序</li>
</ul>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sudo -i</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export XDG_RUNTIME_DIR=/run/user/$(id -u ubuntu)/ &amp;&amp; export WAYLAND_DISPLAY=wayland-1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">gst-launch-1.0 -e --gst-debug=1 qtiqmmfsrc name=camsrc camera=0 ! video/x-raw,format=NV12 ! tee name=split ! queue ! qtivcomposer name=mixer sink_1::alpha=0.5 ! queue ! fpsdisplaysink sync=true signal-fps-measurements=true text-overlay=true video-sink=&quot;waylandsink fullscreen=true&quot; split. ! queue ! qtimlvconverter ! queue ! qtimltflite delegate=external external-delegate-path=libQnnTFLiteDelegate.so external-delegate-options=&quot;QNNExternalDelegate,backend_type=htp;&quot; model=/opt/hrnet_pose_quantized.tflite ! queue ! qtimlvpose threshold=51.0 results=2 module=hrnet labels=/opt/hrnet_pose.labels constants=&quot;hrnet,q-offsets=&lt;8.0&gt;,q-scales=&lt;0.0040499246679246426&gt;;&quot; ! video/x-raw,format=BGRA,width=640,height=360 ! queue ! mixer.</span><br></span></code></pre></div></div>
<ul>
<li>效果图如下：</li>
</ul>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-21-f68564401dde9af3270e947cddd533a9.png" width="864" height="534" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="通过录制好的-mp4-文件获取图像信息实现-ai-功能的示例程序">通过录制好的 MP4 文件获取图像信息实现 AI 功能的示例程序<a href="#通过录制好的-mp4-文件获取图像信息实现-ai-功能的示例程序" class="hash-link" aria-label="Direct link to 通过录制好的 MP4 文件获取图像信息实现 AI 功能的示例程序" title="Direct link to 通过录制好的 MP4 文件获取图像信息实现 AI 功能的示例程序">​</a></h4>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="图像分类image-classification-litert-from-file">图像分类(image-classification-LiteRT-from-file)<a href="#图像分类image-classification-litert-from-file" class="hash-link" aria-label="Direct link to 图像分类(image-classification-LiteRT-from-file)" title="Direct link to 图像分类(image-classification-LiteRT-from-file)">​</a></h5>
<p>该示例程序使用 MP4 文件获取图像并传送给LiteRT使用HTP推理resnet101-resnet101-w8a8.tflite模型，然后将分类结果和图像信息通过weston显示在显示器上。具体pipeline参见下面框图。</p>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-9-8b28dec8cc32e984ba3a0f70c9c5db6e.png" width="1775" height="664" class="img_ev3q"></p>
<ul>
<li>从模型压缩包内将该示例需要的模型文件和label文件push到/opt目录下面</li>
</ul>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">adb push resnet101-resnet101-w8a8.tflite /opt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">adb push classification.labels /opt</span><br></span></code></pre></div></div>
<ul>
<li>执行下面命令运行该示例程序</li>
</ul>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sudo -i</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export XDG_RUNTIME_DIR=/run/user/$(id -u ubuntu)/ &amp;&amp; export WAYLAND_DISPLAY=wayland-1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">gst-launch-1.0 -v --gst-debug=2 filesrc location=/opt/Draw_1080p_180s_30FPS.mp4 ! qtdemux ! h264parse ! v4l2h264dec capture-io-mode=4 output-io-mode=4 ! video/x-raw,format=NV12 ! tee name=split ! queue ! qtivcomposer name=mixer ! queue ! fpsdisplaysink sync=true signal-fps-measurements=true text-overlay=true video-sink=&quot;waylandsink fullscreen=true&quot; split. ! queue ! qtimlvconverter ! queue ! qtimltflite name=tf_3 delegate=external external-delegate-path=libQnnTFLiteDelegate.so external-delegate-options=&quot;QNNExternalDelegate,backend_type=htp,htp_device_id=(string)0,htp_performance_mode=(string)2,htp_precision=(string)1;&quot;  model=/opt/resnet101-resnet101-w8a8.tflite ! queue ! qtimlvclassification threshold=51.0 results=5 module=mobilenet labels=/opt/classification_0.labels extra-operation=softmax constants=&quot;Inception,q-offsets=&lt;-38.0&gt;,q-scales=&lt;0.17039915919303894&gt;;&quot; ! video/x-raw,format=BGRA,width=640,height=360 ! queue ! mixer. </span><br></span></code></pre></div></div>
<ul>
<li>效果图如下：</li>
</ul>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-18-5d1382a3bbb82a0dc9cf91b347fbb60b.jpg" width="1280" height="960" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="目标检测object-detection-litert-from-file">目标检测(object-detection-LiteRT-from-file)<a href="#目标检测object-detection-litert-from-file" class="hash-link" aria-label="Direct link to 目标检测(object-detection-LiteRT-from-file)" title="Direct link to 目标检测(object-detection-LiteRT-from-file)">​</a></h5>
<p>该示例程序使用 MP4 文件获取图像并传送给LiteRT使用HTP推理yolov8_det_quantized.tflite模型，然后将物体检测结果和图像信息通过weston显示在显示器上。具体pipeline参见下面框图。</p>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-10-e0448a1308b3be765b03f134f454420a.png" width="1769" height="653" class="img_ev3q"></p>
<ul>
<li>从模型压缩包内将该示例需要的模型文件和label文件push到/opt目录下面</li>
</ul>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">adb push yolov8_det_quantized.tflite /opt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">adb push yolov8.labels /opt</span><br></span></code></pre></div></div>
<ul>
<li>执行下面命令运行该示例程序</li>
</ul>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sudo -i</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export XDG_RUNTIME_DIR=/run/user/$(id -u ubuntu)/ &amp;&amp; export WAYLAND_DISPLAY=wayland-1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">gst-launch-1.0 -v --gst-debug=2 filesrc location=/opt/Draw_1080p_180s_30FPS.mp4 ! qtdemux ! h264parse ! v4l2h264dec capture-io-mode=4 output-io-mode=4 ! video/x-raw,format=NV12 ! tee name=split ! queue ! qtivcomposer name=mixer ! queue ! fpsdisplaysink sync=true signal-fps-measurements=true text-overlay=true video-sink=&quot;waylandsink fullscreen=true&quot; split. ! queue ! qtimlvconverter ! queue ! qtimltflite delegate=external external-delegate-path=libQnnTFLiteDelegate.so external-delegate-options=&quot;QNNExternalDelegate,backend_type=htp;&quot; model=/opt/yolov8_det_quantized.tflite ! queue ! qtimlvdetection threshold=75.0 results=10 module=yolov8 labels=/opt/yolov8.labels constants=&quot;YOLOv8,q-offsets=&lt;21.0, 0.0, 0.0&gt;,    q-scales=&lt;3.0546178817749023, 0.003793874057009816, 1.0&gt;;&quot; ! video/x-raw,format=BGRA,width=640,height=360 ! queue ! mixer.</span><br></span></code></pre></div></div>
<ul>
<li>效果图如下：</li>
</ul>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-22-29fb4dee3b1a7948034a312f8bfa8709.png" width="956" height="486" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="语义分割image-segmentation-litert-from-file">语义分割(image-segmentation-LiteRT-from-file)<a href="#语义分割image-segmentation-litert-from-file" class="hash-link" aria-label="Direct link to 语义分割(image-segmentation-LiteRT-from-file)" title="Direct link to 语义分割(image-segmentation-LiteRT-from-file)">​</a></h5>
<p>该示例程序使用 MP4 文件获取图像并传送给LiteRT使用HTP推理deeplabv3_plus_mobilenet_quantized.tflite模型，然后将语义分割结果和图像信息通过weston显示在显示器上。具体pipeline参见下面框图。</p>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-11-0eac5d81bcbe3b4f02aa188fb43bb8bd.png" width="1761" height="673" class="img_ev3q"></p>
<ul>
<li>从模型压缩包内将该示例需要的模型文件和label文件push到/opt目录下面</li>
</ul>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">adb push deeplabv3_plus_mobilenet_quantized.tflite /opt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">adb push deeplabv3_resnet50.labels  /opt</span><br></span></code></pre></div></div>
<ul>
<li>执行下面命令运行该示例程序</li>
</ul>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sudo -i</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export XDG_RUNTIME_DIR=/run/user/$(id -u ubuntu)/ &amp;&amp; export WAYLAND_DISPLAY=wayland-1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">gst-launch-1.0 -v --gst-debug=2 filesrc location=/opt/Draw_1080p_180s_30FPS.mp4 ! qtdemux ! h264parse ! v4l2h264dec capture-io-mode=4 output-io-mode=4 ! video/x-raw,format=NV12 ! tee name=split ! queue ! qtivcomposer name=mixer sink_1::alpha=0.5 ! queue ! fpsdisplaysink sync=true signal-fps-measurements=true text-overlay=true video-sink=&quot;waylandsink fullscreen=true&quot; split. ! queue ! qtimlvconverter ! queue ! qtimltflite delegate=external external-delegate-path=libQnnTFLiteDelegate.so external-delegate-options=&quot;QNNExternalDelegate,backend_type=htp;&quot; model=/opt/deeplabv3_plus_mobilenet_quantized.tflite ! queue ! qtimlvsegmentation module=deeplab-argmax labels=/opt/deeplabv3_resnet50.labels constants=&quot;deeplab,q-offsets=&lt;-61.0&gt;,q-scales=&lt;0.06232302635908127&gt;;&quot; ! video/x-raw,format=BGRA,width=256,height=144 ! queue ! mixer.</span><br></span></code></pre></div></div>
<ul>
<li>效果图如下：</li>
</ul>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-23-1a966d6b57441eb8d7c1e07a78935316.png" width="918" height="519" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="姿态识别pose-detection-litert-from-file">姿态识别(pose-detection-LiteRT-from-file)<a href="#姿态识别pose-detection-litert-from-file" class="hash-link" aria-label="Direct link to 姿态识别(pose-detection-LiteRT-from-file)" title="Direct link to 姿态识别(pose-detection-LiteRT-from-file)">​</a></h5>
<p>该示例程序使用 MP4 文件获取图像并传送给LiteRT使用HTP推理hrnet_pose_quantized.tflite模型，然后将人体姿态识别结果和图像信息通过weston显示在显示器上。具体pipeline参见下面框图。</p>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-12-d825e458951e307dbf03c5390f008107.png" width="1756" height="671" class="img_ev3q"></p>
<ul>
<li>从模型压缩包内将该示例需要的模型文件和label文件push到/opt目录下面</li>
</ul>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">adb push hrnet_pose_quantized.tflite /opt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">adb push hrnet_pose.labels  /opt</span><br></span></code></pre></div></div>
<ul>
<li>执行下面命令运行该示例程序</li>
</ul>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sudo -i</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export XDG_RUNTIME_DIR=/run/user/$(id -u ubuntu)/ &amp;&amp; export WAYLAND_DISPLAY=wayland-1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">gst-launch-1.0 -v --gst-debug=2 filesrc location=/opt/Draw_1080p_180s_30FPS.mp4 ! qtdemux ! h264parse ! v4l2h264dec capture-io-mode=4 output-io-mode=4 ! video/x-raw,format=NV12 ! tee name=split ! queue ! qtivcomposer name=mixer sink_1::alpha=0.5 ! queue ! fpsdisplaysink sync=true signal-fps-measurements=true text-overlay=true video-sink=&quot;waylandsink fullscreen=true&quot; split. ! queue ! qtimlvconverter ! queue ! qtimltflite delegate=external external-delegate-path=libQnnTFLiteDelegate.so external-delegate-options=&quot;QNNExternalDelegate,backend_type=htp;&quot; model=/opt/hrnet_pose_quantized.tflite ! queue ! qtimlvpose threshold=51.0 results=2 module=hrnet labels=/opt/hrnet_pose.labels constants=&quot;hrnet,q-offsets=&lt;8.0&gt;,q-scales=&lt;0.0040499246679246426&gt;;&quot; ! video/x-raw,format=BGRA,width=640,height=360 ! queue ! mixer.</span><br></span></code></pre></div></div>
<ul>
<li>效果图如下：</li>
</ul>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-21-f68564401dde9af3270e947cddd533a9.png" width="864" height="534" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="snpe示例程序">SNPE示例程序<a href="#snpe示例程序" class="hash-link" aria-label="Direct link to SNPE示例程序" title="Direct link to SNPE示例程序">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="通过摄像头获取图像信息实现-ai-功能的示例程序-1">通过摄像头获取图像信息实现 AI 功能的示例程序<a href="#通过摄像头获取图像信息实现-ai-功能的示例程序-1" class="hash-link" aria-label="Direct link to 通过摄像头获取图像信息实现 AI 功能的示例程序" title="Direct link to 通过摄像头获取图像信息实现 AI 功能的示例程序">​</a></h4>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="图像分类image-classification-litert-from-camera-1">图像分类(image-classification-LiteRT-from-camera)<a href="#图像分类image-classification-litert-from-camera-1" class="hash-link" aria-label="Direct link to 图像分类(image-classification-LiteRT-from-camera)" title="Direct link to 图像分类(image-classification-LiteRT-from-camera)">​</a></h5>
<p>该示例程序使用camera实时获取图像并传送给SNPE使用HTP推理inceptionv3.dlc模型，然后将分类结果和图像信息通过weston显示在显示器上。具体pipeline参见下面框图。</p>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-13-f7a4d3b6ad8187254b01dba4f5e0930b.png" width="2964" height="1148" class="img_ev3q"></p>
<ul>
<li>从模型压缩包内将该示例需要的模型文件和label文件push到/opt目录下面</li>
</ul>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">adb push inceptionv3.dlc /opt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">adb push classification.labels /opt</span><br></span></code></pre></div></div>
<ul>
<li>执行下面命令运行该示例程序</li>
</ul>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sudo -i</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export XDG_RUNTIME_DIR=/run/user/$(id -u ubuntu)/ &amp;&amp; export WAYLAND_DISPLAY=wayland-1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">gst-launch-1.0 -e --gst-debug=1 qtiqmmfsrc name=camsrc camera=0 ! video/x-raw,format=NV12 ! queue ! tee name=split ! queue ! qtivcomposer name=mixer ! queue ! fpsdisplaysink sync=true text-overlay=true video-sink=&quot;waylandsink sync=true fullscreen=true&quot;  split. ! queue ! qtimlvconverter ! queue ! qtimlsnpe delegate=dsp model=/opt/inceptionv3.dlc ! queue ! qtimlvclassification threshold=40.0 results=2 module=mobilenet labels=/opt/classification.labels ! queue ! video/x-raw,format=BGRA,width=640,height=360 ! queue ! mixer.</span><br></span></code></pre></div></div>
<ul>
<li>效果图如下：</li>
</ul>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-22-29fb4dee3b1a7948034a312f8bfa8709.png" width="956" height="486" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="目标检测object-detection-litert-from-camera-1">目标检测(object-detection-LiteRT-from-camera)<a href="#目标检测object-detection-litert-from-camera-1" class="hash-link" aria-label="Direct link to 目标检测(object-detection-LiteRT-from-camera)" title="Direct link to 目标检测(object-detection-LiteRT-from-camera)">​</a></h5>
<p>该示例程序使用camera实时获取图像并传送给SNPE使用HTP推理yolonas.labels模型，然后将目标检测结果和图像信息通过weston显示在显示器上。具体pipeline参见下面框图。</p>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-14-2e6299f7a017dadd6272fe36df6087f3.png" width="2964" height="1148" class="img_ev3q"></p>
<ul>
<li>从模型压缩包内将该示例需要的模型文件和label文件push到/opt目录下面</li>
</ul>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">adb push yolonas.dlc /opt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">adb push yolonas.labels /opt</span><br></span></code></pre></div></div>
<ul>
<li>执行下面命令运行该示例程序</li>
</ul>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sudo -i</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export XDG_RUNTIME_DIR=/run/user/$(id -u ubuntu)/ &amp;&amp; export WAYLAND_DISPLAY=wayland-1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">gst-launch-1.0 -e --gst-debug=1 qtiqmmfsrc name=camsrc camera=0 ! video/x-raw,format=NV12 ! tee name=split split. ! queue ! qtivcomposer name=mixer ! queue ! fpsdisplaysink sync=true signal-fps-measurements=true text-overlay=true video-sink=&#x27;waylandsink fullscreen=true sync=true&#x27; split. ! queue ! qtimlvconverter ! queue ! qtimlsnpe delegate=dsp model=/opt/yolonas.dlc layers=&quot;&lt;/heads/Mul, /heads/Sigmoid&gt;&quot; ! queue ! qtimlvdetection module=yolo-nas labels=/opt/yolonas.labels ! video/x-raw,format=BGRA ! queue ! mixer.</span><br></span></code></pre></div></div>
<ul>
<li>效果图如下：</li>
</ul>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-21-f68564401dde9af3270e947cddd533a9.png" width="864" height="534" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="通过录制好的-mp4-文件获取图像信息实现-ai-功能的示例程序-1">通过录制好的 MP4 文件获取图像信息实现 AI 功能的示例程序<a href="#通过录制好的-mp4-文件获取图像信息实现-ai-功能的示例程序-1" class="hash-link" aria-label="Direct link to 通过录制好的 MP4 文件获取图像信息实现 AI 功能的示例程序" title="Direct link to 通过录制好的 MP4 文件获取图像信息实现 AI 功能的示例程序">​</a></h4>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="图像分类image-classification-litert-from-file-1">图像分类(image-classification-LiteRT-from-file)<a href="#图像分类image-classification-litert-from-file-1" class="hash-link" aria-label="Direct link to 图像分类(image-classification-LiteRT-from-file)" title="Direct link to 图像分类(image-classification-LiteRT-from-file)">​</a></h5>
<p>该示例程序使用 MP4 文件获取图像并传送给SNPE使用HTP推理inceptionv3.dlc模型，然后将分类结果和图像信息通过Weston显示在显示器上。具体pipeline参见下面框图。</p>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-15-e3786e0b91f587b2540a5cc4e52ed603.png" width="1763" height="673" class="img_ev3q"></p>
<ul>
<li>从模型压缩包内将该示例需要的模型文件和label文件push到/opt目录下面</li>
</ul>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">adb push inceptionv3.dlc /opt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">adb push classification.labels /opt</span><br></span></code></pre></div></div>
<ul>
<li>执行下面命令运行该示例程序</li>
</ul>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sudo -i</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export XDG_RUNTIME_DIR=/run/user/$(id -u ubuntu)/ &amp;&amp; export WAYLAND_DISPLAY=wayland-1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">gst-launch-1.0 -e filesrc location=/opt/Draw_1080p_180s_30FPS.mp4 ! qtdemux ! queue ! h264parse ! v4l2h264dec capture-io-mode=4 output-io-mode=4 ! video/x-raw,format=NV12 ! queue ! tee name=split ! queue ! qtivcomposer name=mixer ! queue ! fpsdisplaysink sync=true text-overlay=true video-sink=&quot;waylandsink sync=true fullscreen=true&quot;  split. ! queue ! qtimlvconverter ! queue ! qtimlsnpe delegate=dsp model=/opt/inceptionv3.dlc ! queue ! qtimlvclassification threshold=40.0 results=2 module=mobilenet labels=/opt/classification.labels ! queue ! video/x-raw,format=BGRA,width=640,height=360 ! queue ! mixer.</span><br></span></code></pre></div></div>
<ul>
<li>效果图如下：</li>
</ul>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-18-5d1382a3bbb82a0dc9cf91b347fbb60b.jpg" width="1280" height="960" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="目标检测object-detection-litert-from-file-1">目标检测(object-detection-LiteRT-from-file)<a href="#目标检测object-detection-litert-from-file-1" class="hash-link" aria-label="Direct link to 目标检测(object-detection-LiteRT-from-file)" title="Direct link to 目标检测(object-detection-LiteRT-from-file)">​</a></h5>
<p>该示例程序使用 MP4 文件获取图像并传送给SNPE使用HTP推理yolonas.labels模型，然后将目标检测结果和图像信息通过Weston显示在显示器上。具体pipeline参见下面框图。</p>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-16-eb83bd95ab9b6d854d7dc04bc775a4dc.png" width="1763" height="687" class="img_ev3q"></p>
<ul>
<li>从模型压缩包内将该示例需要的模型文件和label文件push到/opt目录下面</li>
</ul>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">adb push yolonas.dlc /opt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">adb push yolonas.labels /opt</span><br></span></code></pre></div></div>
<ul>
<li>执行下面命令运行该示例程序</li>
</ul>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sudo -i</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export XDG_RUNTIME_DIR=/run/user/$(id -u ubuntu)/ &amp;&amp; export WAYLAND_DISPLAY=wayland-1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">gst-launch-1.0 -e --gst-debug=2 filesrc location=/opt/Draw_1080p_180s_30FPS.mp4 ! qtdemux ! queue ! h264parse ! v4l2h264dec capture-io-mode=4 output-io-mode=4 ! video/x-raw,format=NV12 ! tee name=split split. ! queue ! qtivcomposer name=mixer ! queue ! fpsdisplaysink sync=true signal-fps-measurements=true text-overlay=true video-sink=&#x27;waylandsink fullscreen=true sync=true&#x27; split. ! queue ! qtimlvconverter ! queue ! qtimlsnpe delegate=dsp model=/opt/yolonas.dlc layers=&quot;&lt;/heads/Mul, /heads/Sigmoid&gt;&quot; ! queue ! qtimlvdetection module=yolo-nas labels=/opt/yolonas.labels ! video/x-raw,format=BGRA ! queue ! mixer.</span><br></span></code></pre></div></div>
<ul>
<li>效果图如下：</li>
</ul>
<p><img decoding="async" loading="lazy" src="/rubikpi-ubuntu-user-manual-test.github.io/assets/images/diagram-22-29fb4dee3b1a7948034a312f8bfa8709.png" width="956" height="486" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="ai-相关插件的用途和功能">AI 相关插件的用途和功能<a href="#ai-相关插件的用途和功能" class="hash-link" aria-label="Direct link to AI 相关插件的用途和功能" title="Direct link to AI 相关插件的用途和功能">​</a></h3>
<table><thead><tr><th>插件名字</th><th>功能</th></tr></thead><tbody><tr><td>qtimlsnpe</td><td>负责snpe的dlc模型文件的加载和执行。它的输入接收来自预处理插件（qtimlvconverter）输出的张量，它的输出是传递给如qtimlvclassification/ qtimlvdetection/qtimlvsegmentation/  qtimlvpose插件的张量。</td></tr><tr><td>qtimltflite</td><td>负责LiteRT的tflite模型文件的加载和执行。它的输入接收来自预处理插件（qtimlvconverter）输出的张量，它的输出是传递给如qtimlvclassification/ qtimlvdetection/qtimlvsegmentation/qtimlvpose插件的张量。</td></tr><tr><td>qtimlvconverter</td><td>将传入视频缓冲区中的数据转换为神经网络张量,同时执行所需的格式转换和大小调整。</td></tr><tr><td>qtimlvclassification</td><td>对分类用例的输出张量进行后处理。</td></tr><tr><td>qtimlvdetection</td><td>对检测用例的输出张量进行后处理。</td></tr><tr><td>qtimlvsegmentation</td><td>对像素类用例的输出张量进行后处理,例如图像分割、深度图处理等。</td></tr><tr><td>qtimlvpose</td><td>对姿势估计用例的输出张量进行后处理。</td></tr></tbody></table></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/hongyang-rp/rubikpi-ubuntu-user-manual-test.github.io/tree/main/docs/Document Home/8.人工智能.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/rubikpi-ubuntu-user-manual-test.github.io/docs/Document Home/摄像头软件"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">摄像头软件</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/rubikpi-ubuntu-user-manual-test.github.io/docs/Document Home/ubuntu-desktop-vs-server"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">ubuntu-desktop-vs-server</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#概述" class="table-of-contents__link toc-highlight">概述</a></li><li><a href="#软件和硬件架构" class="table-of-contents__link toc-highlight">软件和硬件架构</a><ul><li><a href="#ai整体框架" class="table-of-contents__link toc-highlight">AI整体框架</a></li><li><a href="#ai硬件" class="table-of-contents__link toc-highlight">AI硬件</a></li><li><a href="#ai-软件" class="table-of-contents__link toc-highlight">AI 软件</a></li></ul></li><li><a href="#编译和优化模型" class="table-of-contents__link toc-highlight">编译和优化模型</a><ul><li><a href="#ai-hub" class="table-of-contents__link toc-highlight">AI Hub</a><ul><li><a href="#环境配置" class="table-of-contents__link toc-highlight">环境配置</a></li><li><a href="#ai-hub-工作流程" class="table-of-contents__link toc-highlight">AI Hub 工作流程</a></li></ul></li><li><a href="#litert" class="table-of-contents__link toc-highlight">LiteRT</a></li><li><a href="#qualcomm-ai-runtime-sdk" class="table-of-contents__link toc-highlight">Qualcomm AI Runtime SDK</a></li></ul></li><li><a href="#aiml-示例程序" class="table-of-contents__link toc-highlight">AI/ML 示例程序</a><ul><li><a href="#前提准备" class="table-of-contents__link toc-highlight">前提准备</a></li><li><a href="#litert示例程序" class="table-of-contents__link toc-highlight">LiteRT示例程序:</a><ul><li><a href="#通过摄像头获取图像信息实现-ai-功能的示例程序" class="table-of-contents__link toc-highlight">通过摄像头获取图像信息实现 AI 功能的示例程序</a></li><li><a href="#通过录制好的-mp4-文件获取图像信息实现-ai-功能的示例程序" class="table-of-contents__link toc-highlight">通过录制好的 MP4 文件获取图像信息实现 AI 功能的示例程序</a></li></ul></li><li><a href="#snpe示例程序" class="table-of-contents__link toc-highlight">SNPE示例程序</a><ul><li><a href="#通过摄像头获取图像信息实现-ai-功能的示例程序-1" class="table-of-contents__link toc-highlight">通过摄像头获取图像信息实现 AI 功能的示例程序</a></li><li><a href="#通过录制好的-mp4-文件获取图像信息实现-ai-功能的示例程序-1" class="table-of-contents__link toc-highlight">通过录制好的 MP4 文件获取图像信息实现 AI 功能的示例程序</a></li></ul></li><li><a href="#ai-相关插件的用途和功能" class="table-of-contents__link toc-highlight">AI 相关插件的用途和功能</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/qualcomm" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://x.com/Qualcomm" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/rubikpi-ubuntu-user-manual-test.github.io/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/rubikpi-ai" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>